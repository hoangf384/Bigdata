{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc776c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lit, when, col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Local-ETL-Test\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", 256 * 1024 * 1024) # 256 * 1024 * 1024 bytes\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") # 200 partitions for shuffle operations\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c831b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/data/raw/log_content/\" \n",
    "save_path = \"/data/destination/log_content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66af65ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Spark session\n",
    "# ------------------------\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ETL-30Days-v2\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", 256 * 1024 * 1024)\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "MYSQL_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"3306\",\n",
    "    \"database\": \"etl_data\",\n",
    "    \"table\": \"customer_content_stats\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a602f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Paths (update as needed)\n",
    "# -------------------------\n",
    "\n",
    "folder_path = \"/data/raw/log_content/\"\n",
    "save_path = \"/data/destination/log_content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1cb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Helpers: IO\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "def read_data(spark, path):\n",
    "    \"\"\"\n",
    "    Đọc dữ liệu JSON vào Spark DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spark : pyspark.sql.SparkSession\n",
    "        SparkSession đang hoạt động, dùng để đọc dữ liệu.\n",
    "    path : str\n",
    "        Đường dẫn tới file JSON hoặc thư mục chứa nhiều file JSON.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame chứa dữ liệu JSON với schema được Spark tự suy luận.\n",
    "    \"\"\"\n",
    "    df = spark.read.json(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_data(result, path):\n",
    "    \"\"\"\n",
    "    Ghi Spark DataFrame ra file CSV.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result : pyspark.sql.DataFrame\n",
    "        DataFrame chứa dữ liệu đầu ra cần ghi.\n",
    "    path : str\n",
    "        Đường dẫn thư mục lưu file CSV kết quả.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Hàm không trả về giá trị, chỉ thực hiện ghi dữ liệu ra đĩa.\n",
    "    \"\"\"\n",
    "    (\n",
    "        result\n",
    "        .repartition(1)\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .csv(path)\n",
    "    )\n",
    "    print(f\"Data saved to {path}\")\n",
    "\n",
    "\n",
    "def import_to_mysql(df, config):\n",
    "    \"\"\"\n",
    "    Ghi Spark DataFrame vào MySQL bằng JDBC.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame chứa dữ liệu cần ghi vào MySQL.\n",
    "    config : dict\n",
    "        Cấu hình kết nối MySQL, bao gồm host, port, database,\n",
    "        table, user, password và driver.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Hàm không trả về giá trị.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"jdbc:mysql://{config['host']}:{config['port']}/{config['database']}\"\n",
    "\n",
    "    (\n",
    "        df.write\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", url)\n",
    "        .option(\"driver\", config[\"driver\"])\n",
    "        .option(\"dbtable\", config[\"table\"])\n",
    "        .option(\"user\", config[\"user\"])\n",
    "        .option(\"password\", config[\"password\"])\n",
    "        .mode(\"append\")\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "    print(\"Data imported successfully to MySQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b02f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Transform steps\n",
    "# -------------------------\n",
    "\n",
    "def select_fields(df):\n",
    "    \"\"\"\n",
    "    Chọn các trường dữ liệu từ cột `_source` nếu dữ liệu JSON có cấu trúc lồng.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame đầu vào, có thể chứa cột `_source` hoặc đã là dữ liệu phẳng.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame đã được làm phẳng bằng cách chọn `_source.*` nếu cột\n",
    "        `_source` tồn tại; ngược lại trả về DataFrame ban đầu.\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"_source\" in df.columns:\n",
    "        return df.select(\"_source.*\")\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "def transform_category(df):\n",
    "    \"\"\"\n",
    "    Ánh xạ giá trị AppName sang nhóm nội dung (Type).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame đầu vào, bắt buộc phải có cột `AppName`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame đầu ra với cột mới `Type`, biểu diễn nhóm nội dung\n",
    "        tương ứng với từng giá trị `AppName`.\n",
    "    \"\"\"\n",
    "    return df.withColumn(\n",
    "        \"Type\",\n",
    "        when(col(\"AppName\").isin(\"CHANNEL\", \"DSHD\", \"KPLUS\", \"KPlus\"), \"Truyen Hinh\")\n",
    "        .when(col(\"AppName\").isin(\"VOD\", \"FIMS_RES\", \"BHD_RES\", \"VOD_RES\", \"FIMS\", \"BHD\", \"DANET\"), \"Phim Truyen\")\n",
    "        .when(col(\"AppName\") == \"RELAX\", \"Giai Tri\")\n",
    "        .when(col(\"AppName\") == \"CHILD\", \"Thieu Nhi\")\n",
    "        .when(col(\"AppName\") == \"SPORT\", \"The Thao\")\n",
    "        .otherwise(\"Error\")\n",
    "    )\n",
    "\n",
    "\n",
    "def pivot_table(df):\n",
    "    \"\"\"\n",
    "    Tổng hợp và xoay bảng dữ liệu theo nhóm nội dung.\n",
    "\n",
    "    Hàm chuyển dữ liệu từ dạng dài (long format):\n",
    "        (Contract, Type, TotalDuration)\n",
    "    sang dạng rộng (wide format):\n",
    "        1 dòng / Contract, mỗi cột là một loại nội dung.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pyspark.sql.DataFrame\n",
    "        DataFrame đầu vào, bắt buộc phải có các cột:\n",
    "        `Contract`, `Type`, `TotalDuration`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyspark.sql.DataFrame\n",
    "        DataFrame đã được tổng hợp và pivot, trong đó:\n",
    "        - Mỗi dòng tương ứng với một `Contract`.\n",
    "        - Mỗi cột tương ứng với một giá trị `Type`.\n",
    "        - Giá trị ô là tổng `TotalDuration` của từng loại nội dung.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Dữ liệu được tổng hợp bằng `SUM(TotalDuration)` theo\n",
    "      từng cặp (`Contract`, `Type`).\n",
    "    - Các giá trị bị thiếu sau khi pivot sẽ được điền bằng 0.\n",
    "    - Output DataFrame có grain là 1 dòng trên mỗi `Contract`,\n",
    "      phù hợp cho các bước phân tích OLAP tiếp theo.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) groupBy Contract,Type và sum TotalDuration\n",
    "    summary = (\n",
    "        df.groupBy(\"Contract\", \"Type\")\n",
    "          .agg(F.sum(F.col(\"TotalDuration\").cast(\"long\")).alias(\"TotalDuration\"))\n",
    "    )\n",
    "\n",
    "    # 2) pivot để tạo cột cho mỗi Type\n",
    "    pivoted = (\n",
    "        summary.groupBy(\"Contract\")\n",
    "               .pivot(\"Type\")\n",
    "               .sum(\"TotalDuration\")\n",
    "               .na.fill(0)\n",
    "    )\n",
    "    final = (\n",
    "        pivoted.GroupBy(\"Contract\").agg(\n",
    "            F.sum(\"Truyen Hinh\").alias(\"Truyen Hinh\"),\n",
    "            F.sum(\"Giai Tri\").alias(\"Giai Tri\"),\n",
    "            F.sum(\"Thieu Nhi\").alias(\"Thieu Nhi\"),\n",
    "            F.sum(\"The Thao\").alias(\"The Thao\"),\n",
    "            F.sum(\"Phim Truyen\").alias(\"Phim Truyen\"),\n",
    "        )\n",
    "    )\n",
    "    return final\n",
    "\n",
    "\n",
    "def most_watch(df):\n",
    "    # define most_watch\n",
    "    df= df.withColumn(\"MostWatch\", \n",
    "                     F.greatest(col(\"Giai Tri\"), col(\"Phim Truyen\"), col(\"The Thao\"), col(\"Thieu Nhi\"), col(\"Truyen Hinh\"))\n",
    "                     )\n",
    "    df= df.withColumn(\"MostWatch\",\n",
    "                    when(col(\"MostWatch\") == col(\"Truyen Hinh\"),\"Truyen Hinh\").\n",
    "                    when(col(\"MostWatch\") == col(\"Phim Truyen\"),\"Phim Truyen\").\n",
    "                    when(col(\"MostWatch\") == col(\"The Thao\"),\"The Thao\").\n",
    "                    when(col(\"MostWatch\") == col(\"Thieu Nhi\"),\"Thieu Nhi\").\n",
    "                    when(col(\"MostWatch\") == col(\"Giai Tri\"),\"Giai Tri\")\n",
    "                    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def customer_taste(df):\n",
    "    # define customer_taste\n",
    "    df=df.withColumn(\"Taste\", \n",
    "                     F.concat_ws(\"-\",\n",
    "                                 when(col(\"Giai Tri\") != 0, lit(\"Giai Tri\")),\n",
    "                                 when(col(\"Phim Truyen\") != 0, lit(\"Phim Truyen\")),\n",
    "                                 when(col(\"The Thao\") != 0, lit(\"The Thao\")),\n",
    "                                 when(col(\"Thieu Nhi\") != 0, lit(\"Thieu Nhi\")),\n",
    "                                 when(col(\"Truyen Hinh\") != 0, lit(\"Truyen Hinh\"))\n",
    "                                 )\n",
    "                    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_active(df):\n",
    "    windowspec = Window.partitionBy(\"Contract\")\n",
    "    df = df.withColumn(\"Active\",F.count(\"Date\").over(windowspec))\n",
    "    df = df.drop(\"Date\")\n",
    "    df = df.withColumn(\"Active\",when(col(\"Active\") > 4,\"High\").otherwise(\"Low\"))\n",
    "    df = df.groupBy(\"Contract\").agg(\n",
    "    F.sum(\"Giai Tri\").alias(\"Total_Giai_Tri\"),\n",
    "    F.sum(\"Phim Truyen\").alias(\"Total_Phim_Truyen\"),\n",
    "    F.sum(\"The Thao\").alias(\"Total_The_Thao\"),\n",
    "    F.sum(\"Thieu Nhi\").alias(\"Total_Thieu_Nhi\"),\n",
    "    F.sum(\"Truyen Hinh\").alias(\"Total_Truyen_Hinh\"),\n",
    "    F.first(\"MostWacth\").alias(\"MostWacth\"),\n",
    "    F.first(\"Taste\").alias(\"Taste\"),\n",
    "    F.first(\"Active\").alias(\"Active\")\n",
    ")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8861df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quản lý flow 1-30 days\n",
    "# List files\n",
    "def list_files_sorted(path):\n",
    "    \"\"\"\n",
    "    Liệt kê và sắp xếp các file JSON trong một thư mục.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Đường dẫn tới thư mục chứa các file JSON.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        Danh sách đường dẫn đầy đủ tới các file JSON,\n",
    "        được sắp xếp theo thứ tự tăng dần.\n",
    "    \"\"\"\n",
    "    files = [\n",
    "        os.path.join(path, f)\n",
    "        for f in os.listdir(path)\n",
    "        if f.endswith(\".json\") and os.path.isfile(os.path.join(path, f))\n",
    "    ]\n",
    "    return sorted(files)\n",
    "\n",
    "#-------------------\n",
    "# MISC\n",
    "#-------------------\n",
    "\n",
    "def extract_date_from_filename(path):\n",
    "    \"\"\"\n",
    "    Trích xuất ngày từ tên file JSON và chuyển sang kiểu date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Đường dẫn tới file JSON, với tên file có định dạng `YYYYMMDD.json`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datetime.date\n",
    "        Giá trị ngày được trích xuất từ tên file, ở dạng `datetime.date`.\n",
    "    \"\"\"\n",
    "    \n",
    "    base = os.path.basename(path)      # 20220401.json\n",
    "    date_str = base.split(\".\")[0]   # 20220401\n",
    "    return datetime.strptime(date_str, \"%Y%m%d\").date()\n",
    "\n",
    "# ------\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_files = list_files_sorted(folder_path)\n",
    "    print(\"Files to process:\", all_files)\n",
    "\n",
    "    final_df = None\n",
    "\n",
    "    for file in all_files:\n",
    "        print(f\"Processing file: {file}\")\n",
    "\n",
    "        # Extract date\n",
    "        date_str = extract_date_from_filename(file)\n",
    "\n",
    "        # 1 day ETL\n",
    "        df = read_data(spark, file)\n",
    "        df = select_fields(df)\n",
    "        df = transform_category(df)\n",
    "        \n",
    "        # 2. fillter\n",
    "        df = df.filter((col(\"Contract\").isNotNull()) & (col(\"Contract\") != \"0\"))\n",
    "        df = df.filter(col(\"Type\") != \"Error\")\n",
    "        \n",
    "        # summarize, pivot\n",
    "        df = pivot_table(df)\n",
    "        # add date column\n",
    "        df = df.withColumn(\"Date\", F.lit(date_str))\n",
    "        # them most watch, customer taste\n",
    "        df = most_watch(df)\n",
    "        df = customer_taste(df)\n",
    "\n",
    "        # union all days\n",
    "        if final_df is None:\n",
    "            final_df = df\n",
    "        else:\n",
    "            final_df = final_df.unionByName(df)\n",
    "\n",
    "    print(\"Saving final output...\")\n",
    "    save_data(final_df, save_path)\n",
    "\n",
    "    print(\"---- ETL 30 DAYS COMPLETED ----\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to process (demo 5 days): ['/data/raw/log_content/20220401.json', '/data/raw/log_content/20220402.json', '/data/raw/log_content/20220403.json', '/data/raw/log_content/20220404.json', '/data/raw/log_content/20220405.json']\n",
      "Processing file: /data/raw/log_content/20220401.json\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|KPLUS  |HNH579912|0C96E62FC55C|254          |Truyen Hinh|\n",
      "|KPLUS  |HUFD40665|CCEDDC333614|1457         |Truyen Hinh|\n",
      "|KPLUS  |HNH572635|B068E6A1C5F6|2318         |Truyen Hinh|\n",
      "|KPLUS  |HND141717|08674EE8D2C2|1452         |Truyen Hinh|\n",
      "|KPLUS  |HNH743103|402343C25D7D|251          |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|KPLUS  |HNH579912|0C96E62FC55C|254          |Truyen Hinh|\n",
      "|KPLUS  |HUFD40665|CCEDDC333614|1457         |Truyen Hinh|\n",
      "|KPLUS  |HNH572635|B068E6A1C5F6|2318         |Truyen Hinh|\n",
      "|KPLUS  |HND141717|08674EE8D2C2|1452         |Truyen Hinh|\n",
      "|KPLUS  |HNH743103|402343C25D7D|251          |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing file: /data/raw/log_content/20220402.json\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|VOD    |DTFD19291|B84DEE76AEFC|46486        |Phim Truyen|\n",
      "|VOD    |HDAAA2134|10394E2791E6|13840        |Phim Truyen|\n",
      "|VOD    |SGJ048834|B84DEEFB33E8|13527        |Phim Truyen|\n",
      "|VOD    |NTFD59815|C0B5D7E80AD0|7471         |Phim Truyen|\n",
      "|VOD    |HNJ144088|10394E4299DE|1228         |Phim Truyen|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|VOD    |DTFD19291|B84DEE76AEFC|46486        |Phim Truyen|\n",
      "|VOD    |HDAAA2134|10394E2791E6|13840        |Phim Truyen|\n",
      "|VOD    |SGJ048834|B84DEEFB33E8|13527        |Phim Truyen|\n",
      "|VOD    |NTFD59815|C0B5D7E80AD0|7471         |Phim Truyen|\n",
      "|VOD    |HNJ144088|10394E4299DE|1228         |Phim Truyen|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing file: /data/raw/log_content/20220403.json\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|CHANNEL|TBFD06474|84AA9C3E393E|34120        |Truyen Hinh|\n",
      "|CHANNEL|HNH976100|B84DEEEF1E14|34392        |Truyen Hinh|\n",
      "|CHANNEL|TVD001309|B046FCAA24FB|34119        |Truyen Hinh|\n",
      "|CHANNEL|HNH434192|B05216B7B0A8|34390        |Truyen Hinh|\n",
      "|CHANNEL|AGFD34246|8CC84B700501|34389        |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|CHANNEL|TBFD06474|84AA9C3E393E|34120        |Truyen Hinh|\n",
      "|CHANNEL|HNH976100|B84DEEEF1E14|34392        |Truyen Hinh|\n",
      "|CHANNEL|TVD001309|B046FCAA24FB|34119        |Truyen Hinh|\n",
      "|CHANNEL|HNH434192|B05216B7B0A8|34390        |Truyen Hinh|\n",
      "|CHANNEL|AGFD34246|8CC84B700501|34389        |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing file: /data/raw/log_content/20220404.json\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|CHANNEL|HNJ095119|B84DEEFB4659|48997        |Truyen Hinh|\n",
      "|CHANNEL|NBFD20591|B84DEE84A8CB|48995        |Truyen Hinh|\n",
      "|CHANNEL|SGH497930|90324B36CE66|48994        |Truyen Hinh|\n",
      "|CHANNEL|LDFD16037|84AA9CAB0C94|48993        |Truyen Hinh|\n",
      "|CHANNEL|VTFD15991|9C305B3747B1|48992        |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|CHANNEL|HNJ095119|B84DEEFB4659|48997        |Truyen Hinh|\n",
      "|CHANNEL|NBFD20591|B84DEE84A8CB|48995        |Truyen Hinh|\n",
      "|CHANNEL|SGH497930|90324B36CE66|48994        |Truyen Hinh|\n",
      "|CHANNEL|LDFD16037|84AA9CAB0C94|48993        |Truyen Hinh|\n",
      "|CHANNEL|VTFD15991|9C305B3747B1|48992        |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Processing file: /data/raw/log_content/20220405.json\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|CHANNEL|HUFD52373|B84DEED3189E|45562        |Truyen Hinh|\n",
      "|CHANNEL|DLD023066|9C305B3747EC|44928        |Truyen Hinh|\n",
      "|CHANNEL|HNH487875|84AA9C45BF58|45560        |Truyen Hinh|\n",
      "|CHANNEL|VLFD20963|10394E19A57B|45560        |Truyen Hinh|\n",
      "|CHANNEL|SGH522004|7440BB97D85F|44926        |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|AppName|Contract |Mac         |TotalDuration|Type       |\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "|CHANNEL|HUFD52373|B84DEED3189E|45562        |Truyen Hinh|\n",
      "|CHANNEL|DLD023066|9C305B3747EC|44928        |Truyen Hinh|\n",
      "|CHANNEL|HNH487875|84AA9C45BF58|45560        |Truyen Hinh|\n",
      "|CHANNEL|VLFD20963|10394E19A57B|45560        |Truyen Hinh|\n",
      "|CHANNEL|SGH522004|7440BB97D85F|44926        |Truyen Hinh|\n",
      "+-------+---------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_files = list_files_sorted(folder_path)[:5]\n",
    "print(\"Files to process (demo 5 days):\", all_files)\n",
    "\n",
    "final_df = None\n",
    "\n",
    "for file in all_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    date_str = extract_date_from_filename(file)\n",
    "\n",
    "    df = read_data(spark, file)\n",
    "    df = select_fields(df)\n",
    "    df = transform_category(df)\n",
    "\n",
    "    df.show(5, truncate= False)\n",
    "    \n",
    "    df = df.filter((col(\"Contract\").isNotNull()) & (col(\"Contract\") != \"0\"))\n",
    "    df = df.filter(col(\"Type\") != \"Error\")\n",
    "    \n",
    "    df.show(5, truncate= False)\n",
    "    \n",
    "    df = pivot_table(df)\n",
    "    df = df.withColumn(\"Date\", F.lit(date_str))\n",
    "    # df = most_watch(df)\n",
    "    # df = customer_taste(df)\n",
    "\n",
    "    if final_df is None:\n",
    "        final_df = df\n",
    "    else:\n",
    "        final_df = final_df.unionByName(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb17a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e042dffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+--------+---------+-----------+----------+\n",
      "|Contract |Giai Tri|Phim Truyen|The Thao|Thieu Nhi|Truyen Hinh|Date      |\n",
      "+---------+--------+-----------+--------+---------+-----------+----------+\n",
      "|HNH798870|0       |799        |0       |0        |1560       |2022-04-01|\n",
      "|HNH772729|0       |0          |0       |0        |82555      |2022-04-01|\n",
      "|BDFD38155|0       |11843      |0       |0        |5395       |2022-04-01|\n",
      "|LAFD18850|0       |0          |0       |0        |40         |2022-04-01|\n",
      "|GLAAA0974|0       |0          |0       |0        |51         |2022-04-01|\n",
      "+---------+--------+-----------+--------+---------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final_df = most_watch(final_df)\n",
    "# final_df = customer_taste(final_df)\n",
    "final_df.show(5, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c5076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662698"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.select(\"Contract\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00faa6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6680184"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4fc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"Contract\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b57fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+\n",
      "|Contract|Date|count|\n",
      "+--------+----+-----+\n",
      "+--------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.groupBy(\"Contract\", \"Date\") \\\n",
    "    .count() \\\n",
    "    .filter(F.col(\"count\") > 1) \\\n",
    "    .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc7341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-----------+--------+---------+-----------+----------+------+\n",
      "|Contract      |Giai Tri|Phim Truyen|The Thao|Thieu Nhi|Truyen Hinh|Date      |Active|\n",
      "+--------------+--------+-----------+--------+---------+-----------+----------+------+\n",
      "|113.182.209.48|89      |0          |0       |0        |63         |2022-04-01|1     |\n",
      "|AGAAA0338     |0       |0          |0       |0        |8895       |2022-04-01|5     |\n",
      "|AGAAA0338     |0       |0          |0       |0        |8315       |2022-04-02|5     |\n",
      "|AGAAA0338     |0       |0          |0       |0        |8894       |2022-04-03|5     |\n",
      "|AGAAA0338     |0       |0          |0       |0        |5971       |2022-04-04|5     |\n",
      "+--------------+--------+-----------+--------+---------+-----------+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.show(5, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-----------+--------+---------+-----------+------+\n",
      "|Contract      |Giai Tri|Phim Truyen|The Thao|Thieu Nhi|Truyen Hinh|Active|\n",
      "+--------------+--------+-----------+--------+---------+-----------+------+\n",
      "|113.182.209.48|89      |0          |0       |0        |63         |1     |\n",
      "|AGAAA0338     |0       |0          |0       |0        |43107      |5     |\n",
      "|AGAAA0342     |0       |0          |0       |0        |8849       |2     |\n",
      "|AGAAA0391     |0       |0          |0       |0        |43653      |2     |\n",
      "|AGAAA0613     |0       |0          |0       |0        |304        |5     |\n",
      "+--------------+--------+-----------+--------+---------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = (\n",
    "    x.groupBy(\"Contract\")\n",
    "     .agg(\n",
    "         F.sum(\"Giai Tri\").alias(\"Giai Tri\"),\n",
    "         F.sum(\"Phim Truyen\").alias(\"Phim Truyen\"),\n",
    "         F.sum(\"The Thao\").alias(\"The Thao\"),\n",
    "         F.sum(\"Thieu Nhi\").alias(\"Thieu Nhi\"),\n",
    "         F.sum(\"Truyen Hinh\").alias(\"Truyen Hinh\"),\n",
    "         F.max(\"Active\").alias(\"Active\")\n",
    "     )\n",
    ")\n",
    "\n",
    "x.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-----------+--------+---------+-----------+------+-----------+--------------------+\n",
      "|Contract      |Giai Tri|Phim Truyen|The Thao|Thieu Nhi|Truyen Hinh|Active|MostWatch  |Taste               |\n",
      "+--------------+--------+-----------+--------+---------+-----------+------+-----------+--------------------+\n",
      "|113.182.209.48|89      |0          |0       |0        |63         |1     |Giai Tri   |Giai Tri-Truyen Hinh|\n",
      "|AGAAA0338     |0       |0          |0       |0        |43107      |5     |Truyen Hinh|Truyen Hinh         |\n",
      "|AGAAA0342     |0       |0          |0       |0        |8849       |2     |Truyen Hinh|Truyen Hinh         |\n",
      "|AGAAA0391     |0       |0          |0       |0        |43653      |2     |Truyen Hinh|Truyen Hinh         |\n",
      "|AGAAA0613     |0       |0          |0       |0        |304        |5     |Truyen Hinh|Truyen Hinh         |\n",
      "+--------------+--------+-----------+--------+---------+-----------+------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = most_watch(x)\n",
    "x = customer_taste(x)\n",
    "x.show(5, truncate= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
